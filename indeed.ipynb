{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import smtplib\n",
    "import spacy\n",
    "import urllib3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from email.message import EmailMessage\n",
    "from sklearn.neighbors import NearestNeighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndeedScraper(object):\n",
    "    \"\"\"Get the long descriptions of Indeed.com job listings.\n",
    "\n",
    "    You supply the base URL.\n",
    "\n",
    "    Go to Indeed.com and enter the job-search term and city.\n",
    "    Right click on the 'Find jobs' button and copy the link.\n",
    "    Paste the link as an argument when instantiating the scraper.\n",
    "\n",
    "    list_o_descriptions = IndeedScraper('http://www.indeed.com/jobs?q=data%20scientist&l=Seattle,%20WA').get_descriptions()\n",
    "\n",
    "    :param url: string URL of job and city to search for.\n",
    "    :param pages: int number of pages to scrape.\n",
    "    :returns list: strings of job descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 pages: int = 10, \n",
    "                 num_jobs: int = 10,\n",
    "                 email: str = None,\n",
    "                 city: str = None,\n",
    "                 state: str = None,\n",
    "                 terms: str = None) -> None:\n",
    "        self.email = self.user_input('Enter email:\\n')\n",
    "        self.city = self.user_input('Enter city:\\n').strip().title()\n",
    "        self.state = self.user_input('Enter state:\\n').strip().upper()\n",
    "        self.terms = self.user_input('Enter job title:\\n').strip().lower()\n",
    "        self.url = self.build_url()\n",
    "        self.http = urllib3.PoolManager()\n",
    "        self.pages = pages\n",
    "        self.num_jobs = num_jobs\n",
    "        self.jobs = set()\n",
    "        self.base_email = 'pkutrich@gmail.com'\n",
    "        self.vectors = None\n",
    "        print('Loading NLP packages...')\n",
    "        self.nlp = spacy.load(\"en_core_web_lg\")\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.num_jobs,\n",
    "                                   algorithm='ball_tree')\n",
    "        self.resume = self.load_resume()\n",
    "        self.descriptions = None\n",
    "        self.main()\n",
    "    \n",
    "    def main(self) -> None:\n",
    "        self.descriptions = self.get_descriptions()\n",
    "        self.vectors = self.get_description_vectors()\n",
    "        self.get_best_jobs()\n",
    "        self.email_jobs()\n",
    "    \n",
    "    def build_url(self) -> None:\n",
    "        url = f\"http://www.indeed.com/jobs?q={'%20'.join(self.terms.split())}&l={'%20'.join(self.city.split())},%20{self.state}\"\n",
    "        print('Search URL: ', url)\n",
    "        return url\n",
    "    \n",
    "    def user_input(self, prompt: str) -> str:\n",
    "        return input(prompt)\n",
    "\n",
    "    def find_long_urls(self, soup: str) -> list:\n",
    "        urls = []\n",
    "        for div in soup.find_all(name='div', \n",
    "                                 attrs={'class': 'row'}):\n",
    "            for a in div.find_all(name='a', \n",
    "                                  attrs={'class': 'jobtitle turnstileLink'}):\n",
    "                urls.append(a['href'])\n",
    "        return urls\n",
    "\n",
    "    def get_next_pages(self) -> None:\n",
    "        return [self.url] + [self.url + f'&start={x}0' for x in range(1, self.pages)]\n",
    "\n",
    "    def get_descriptions(self) -> list:\n",
    "        print('Getting job descriptions...')\n",
    "        descriptions = []\n",
    "        for base_url in self.get_next_pages():\n",
    "            request = self.http.request('GET',\n",
    "                                        base_url)\n",
    "            base_soup = BeautifulSoup(request.data)\n",
    "\n",
    "            for url in self.find_long_urls(base_soup):\n",
    "                the_url = \"http://www.indeed.com/\" + url\n",
    "\n",
    "                req = self.http.request('GET', \n",
    "                                        the_url,\n",
    "                                        headers={'User-Agent': 'opera'},\n",
    "                                        retries=urllib3.Retry(connect=500, \n",
    "                                                              read=2,\n",
    "                                                              redirect=50))\n",
    "\n",
    "                soup = BeautifulSoup(req.data, 'html.parser')\n",
    "                description = soup.find(name='div', \n",
    "                                        attrs={'id': 'jobDescriptionText'})\n",
    "                if description:\n",
    "                    descriptions.append((the_url, description.text))\n",
    "        print(f\"Found {len(descriptions)} jobs.\")\n",
    "        return descriptions\n",
    "    \n",
    "    def load_resume(self) -> str:\n",
    "        print('Loading resume...')\n",
    "        with open('CaiNowicki-2019resume.txt', 'r') as f:\n",
    "            resume = f.read().strip('\\n')\n",
    "        return resume\n",
    "    \n",
    "    def get_description_vectors(self):\n",
    "        print('Getting description vectors...')\n",
    "        return np.array([self.nlp(doc).vector for _, doc in self.descriptions])\n",
    "        \n",
    "    def get_best_jobs(self) -> None:\n",
    "        print(f'Finding best {self.num_jobs} job matches...')\n",
    "        self.nn.fit(self.vectors)\n",
    "        potential_neighbors = self.nn.kneighbors(np.array([self.nlp(self.resume).vector]))\n",
    "        neighbors = [y for x, y in zip(potential_neighbors[0][0], potential_neighbors[1][0]) if 0.05 < x]\n",
    "        for neighbor in neighbors:\n",
    "            self.jobs.add(self.descriptions[neighbor][1])\n",
    "    \n",
    "    def email_jobs(self) -> None:\n",
    "        print('Emailing jobs...')\n",
    "        msg = EmailMessage()\n",
    "        msg['subject'] = \"New jobs!!\"\n",
    "        msg['from'] = self.base_email\n",
    "        msg['to'] = self.email\n",
    "        div = \"\\n\" + \"-\" * 79 + \"\\n\"\n",
    "        msg.set_content(f\"{div}\".join([job.strip() + '\\n' for job in self.jobs]))\n",
    "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        server.starttls()\n",
    "        server.login('pkutrich', 'ozgndzvnrgihyawj')\n",
    "#         server.set_debuglevel(1)\n",
    "        server.send_message(msg)\n",
    "        server.quit()\n",
    "        print(\"You've got mail!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter email:\n",
      " pkutrich@gmail.com\n",
      "Enter city:\n",
      " Raleigh\n",
      "Enter state:\n",
      " nc\n",
      "Enter job title:\n",
      " machine learning engineer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url  http://www.indeed.com/jobs?q=machine%20learning%20engineer&l=Raleigh,%20NC\n",
      "Loading NLP packages...\n",
      "Loading resume...\n",
      "Getting job descriptions...\n",
      "Found 161 jobs.\n",
      "Getting description vectors...\n",
      "Finding best 10 job matches...\n",
      "Emailing jobs...\n",
      "You've got mail!!\n"
     ]
    }
   ],
   "source": [
    "scraper = IndeedScraper(pages=10, num_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Job-finder-FWWmuhfB",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
